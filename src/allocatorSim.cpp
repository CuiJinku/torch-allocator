/**
 * @brief PyTorch CUDA caching allocator
 * @date 12/19/2022
*/

#include "allocatorSim.h"

allocatorSim::allocatorSim() {
}

allocatorSim::~allocatorSim() {
}

void allocatorSim::test_allocator() {
    std::cout << "Hello allocator!" << std::endl;
}
